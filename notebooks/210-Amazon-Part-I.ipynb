{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ciri/iese-dsfb/blob/main/notebooks/210-Amazon-Part-I.ipynb)\n",
    "\n",
    "# Tabular: Amazon Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Familiarization\n",
    "\n",
    "You're working with real Amazon India Female fashion sales data from their Q2 2022 MRP which you can download [here](https://raw.githubusercontent.com/ciri/iese-dsfb/main/resources/tabular/AmazonSalesReport.csv). This dataset provides detailed insights into Amazon sales data, including SKU, product design, category, size, pricing, and fulfillment details. It is useful for analyzing sales performance and optimizing product profitability. Before doing any analysis, you need to understand what data you're looking at:\n",
    "\n",
    "* What does each row represent?\n",
    "* What kind of columns are available?\n",
    "* Are there missing values?\n",
    "\n",
    "First step: always **look at your data**. Use `.head()` to see a sample, `.info()` to understand the structure, and `.describe()` for numeric summaries. We'll answer those questions using a few simple commands in pandas.\n",
    "\n",
    "Some datasets also come with a `data card`, here's the one for this dataset:\n",
    "\n",
    "\n",
    "| **Variable**       | **Description**                                               | **Type**    |\n",
    "|--------------------|---------------------------------------------------------------|-------------|\n",
    "| `category`         | Type of product (e.g., kurta, set, top)                       | String      |\n",
    "| `size`             | Size of the product                                           | String      |\n",
    "| `date`             | Date of the sale                                              | Date        |\n",
    "| `status`           | Status of the order (e.g., Shipped, Cancelled)                | String      |\n",
    "| `fulfilment`       | Who fulfilled the order (Amazon or Merchant)                  | String      |\n",
    "| `style`            | Style identifier of the product                               | String      |\n",
    "| `sku`              | Stock Keeping Unit, unique product ID                         | String      |\n",
    "| `asin`             | Amazon Standard Identification Number                         | String      |\n",
    "| `courier_status`   | Current status of the shipping courier                        | String      |\n",
    "| `qty`              | Quantity of items ordered                                     | Integer     |\n",
    "| `amount`           | Sale amount (in INR)                                          | Float       |\n",
    "| `b2b`              | Whether the customer is a business                            | Boolean     |\n",
    "| `currency`         | Currency used for the transaction (usually INR)               | String      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../resources/tabular/AmazonSalesReport.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may be getting a warning. When pandas loads a CSV, it tries to infer the data type of each column (int, float, object, etc.). If a column has both numbers and text, pandas gets confused. Column 23 (24th column, likely 'fulfilled-by') has mixed types - probably some strings like \"Easy Ship\" and some missing values (NaN) or unexpected values like False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🧹 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can trust or analyze this data, we need to clean it. That means:\n",
    "\n",
    "* Standardize column names so they’re consistent\n",
    "* Drop unnecessary columns (like Excel export leftovers)\n",
    "* Handle missing values in a simple, safe way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop irrelevant columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns # at the end there's a weird one, likely someone added one comma too many or had a value in excel at the end of the row\n",
    "           # we also don't need this index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 22', 'index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rename columns**\n",
    "\n",
    "Let's clean up some column names, ideally in python no spaces. Let's make it all very consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename confusing column names for clarity\n",
    "df = df.rename(columns={\n",
    "    'Order ID': 'order_id',\n",
    "    'Date': 'date',\n",
    "    'Status': 'status',\n",
    "    'Fulfilment': 'fulfilment',\n",
    "    'Sales Channel ': 'sales_channel',\n",
    "    'ship-service-level': 'ship_service_level',\n",
    "    'Style': 'style',\n",
    "    'Category': 'category',\n",
    "    'Size': 'size',\n",
    "    'Courier Status': 'courier_status',\n",
    "    'Qty': 'qty',\n",
    "    'currency': 'currency',\n",
    "    'Amount': 'amount',\n",
    "    'ship-city': 'ship_city',\n",
    "    'ship-state': 'ship_state',\n",
    "    'ship-postal-code': 'ship_postal_code',\n",
    "    'ship-country': 'ship_country',\n",
    "    'promotion-ids': 'promotion_ids',\n",
    "    'fulfilled-by': 'fulfilled_by',\n",
    "})\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handle missing values**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `df.isna()` is a data frame of the same shape as `df`, whose terms have type `bool`. With `sum`, we get the number of `True` values per column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values are denoted by `NaN` in Pandas. When a Pandas object is built, both plain Python’s `None` and NumPy’s `nan` are taken as NaN. Since `np.nan` has type `float`, a numeric series containing NaN values\n",
    "gets type float.\n",
    "\n",
    "Three useful Pandas methods related to missing values, which can be applied to both series and data frames, are:\n",
    "* `isna` returns a Boolean mask indicating which terms are missing.\n",
    "* `fillna` is used for replacing `NaN`’s by a fixed value, set by the user.\n",
    "* `dropna` returns the same data frame minus the rows that contain at least one missing value. If a list of columns is specified, the missing values are searched only for those columns.\n",
    "\n",
    "For our case, let’s apply the following business rules:\n",
    "\n",
    "- If *amount* or *currency* is missing, drop the row (we can't use it for financial analysis).\n",
    "- If *courier status* is missing, fill it with `\"Unknown\"`.\n",
    "\n",
    "The rest we leave as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['amount', 'currency']).copy()\n",
    "df['courier_status'] = df['courier_status'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove Duplicates**\n",
    "\n",
    "There are two useful Pandas functions for managing duplicates:\n",
    "\n",
    "* `drop_duplicates` drops the duplicated entries (in a series) or the duplicated rows (in a data frame).\n",
    "* `duplicated` returns a Boolean series indicating which entries (for a series) or which rows (for a data\n",
    "frame) are duplicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before dropping duplicates:', df.shape)\n",
    "df = df.drop_duplicates()\n",
    "print('After dropping duplicates:', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Any other final conversion**\n",
    "\n",
    "Since I am not too familiar (intuitively) with INR, I prefer to convert to Euro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_rate = 0.0118 # In 2022\n",
    "df['amount_eu'] = (df['amount'] * exchange_rate).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's good practice to save the dataframe after preprocessing this allows you to continue with a clean dataset going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../resources/tabular/Amazon-cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../resources/tabular/Amazon-cleaned.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue Trend over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You try it**\n",
    "\n",
    "Create a new variable / column for revenue. Anything weird going on? \n",
    "\n",
    "Hint: use the `describe()` function or look at the min/max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding time\n",
    "\n",
    "Pandas has powerful tools to help you work with dates - but dates start as plain text (\"strings\"), which can't be analyzed or sorted properly.\n",
    "\n",
    "So first, we **convert the `date` column** into a proper **datetime object**. Once we do that, we unlock a *lot* of cool tricks. Here's the flow:\n",
    "\n",
    "\n",
    "| Concept              | What it Does                                                              |\n",
    "|----------------------|---------------------------------------------------------------------------|\n",
    "| `pd.to_datetime()`   | Converts text into a proper date format                                   |\n",
    "| `.dt`                | A special \"datetime accessor\" in pandas - lets you pull out month, day, etc. |\n",
    "| `.dt.month_name()` | Extracts the **month name** (e.g., \"April\") from a full date              |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df.date.dt.month_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To report sales per month we need to do a groupby.\n",
    "\n",
    "Suppose that you are interested in the average price per room type. You can get this by applying `groupby()` which works as follows:\n",
    "\n",
    "<center>\n",
    "<img src='../images/pandas_groupby.png' width='100%'>\n",
    "</center>\n",
    "\n",
    "\n",
    "This method groups the rows according to one or more **grouping variables**. Here, you specify `groupby(by='room_type')`. \n",
    "\n",
    "Next, you select the columns to be aggregated, which, here would be just `price`. Finally, you specify the **aggregation function**. Having only the mean, you can do it just by adding `mean()` or by specifying `.agg('mean')`. The method `round()` works as you would expect it to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_revenue = df.groupby('month')[['revenue']].sum()\n",
    "monthly_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's order the months correctly and plot\n",
    "# We will also drop March as its clearly incomplete\n",
    "month_order = ['April', 'May', 'June']\n",
    "monthly_revenue = monthly_revenue.loc[month_order]\n",
    "monthly_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average revenue over last 3 months\n",
    "# and how much below/above average we are\n",
    "avg_q2_revenue = monthly_revenue['revenue'].mean()\n",
    "avg_q2_revenue\n",
    "\n",
    "monthly_revenue['% below avg'] = round((1 - monthly_revenue['revenue'] / avg_q2_revenue) * 100, 1)\n",
    "monthly_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charts are often more persuasive than tables. We will not waste time teaching this as you can ask LLM's to provide this to you. You can \"vibe\"-chart your way to great visualizations, just make sure that your dataframe above is 100% correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot bars\n",
    "bars = ax.bar(monthly_revenue.index, monthly_revenue['revenue'], color='#878787')\n",
    "\n",
    "# Add horizontal line for average\n",
    "ax.axhline(avg_q2_revenue, linestyle='--', color='orange', linewidth=2, label='Q2 Average Revenue')\n",
    "\n",
    "# Annotate each bar\n",
    "for bar, pct in zip(bars, monthly_revenue['% below avg']):\n",
    "    ax.annotate(f\"{pct}% below avg.\" if pct > 0 else f\"{abs(pct)}% above avg.\",\n",
    "                xy=(bar.get_x() + bar.get_width()/2, bar.get_height() - 7000),\n",
    "                xytext=(0, 8), textcoords='offset points',\n",
    "                ha='center', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Titles and labels\n",
    "ax.set_title(\"Amazon India Net Revenue\", fontsize=20, x=0.19, y=1.05)\n",
    "ax.text(-0.08, 1.02, \"Q2 FY22\", fontsize=15, color='#878787', transform=ax.transAxes)\n",
    "ax.set_ylabel('Net Revenue in €10,000', fontsize=12, labelpad=3)\n",
    "ax.set_xlabel(None)\n",
    "\n",
    "# Ticks and grid\n",
    "ax.set_yticklabels(list(range(0, 41, 5)))\n",
    "ax.yaxis.grid(linestyle='--', color='gray', linewidth=0.5, dashes=(8, 5))\n",
    "ax.xaxis.grid(False)\n",
    "ax.tick_params(axis='both', labelsize=12)\n",
    "\n",
    "# Spines\n",
    "for spine in ['top', 'right', 'left']:\n",
    "    ax.spines[spine].set_visible(False)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_color('black')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1,1.05), fontsize=12, fancybox=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Analysis: Revenue went down in June, this might be seasonal  or a campaign issue. One month is much higher, need to check if what the reason is (promotion?). Revenue is flat ...market saturation or consistent demand?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You try it**\n",
    "\n",
    "On which days is Amazon earning most of its revenue in India?\n",
    "\n",
    "1. First create a column containing the day of the week. Hint: use `dt.day_name()` for this (day of the week) or alternatively `dt.day` (day of month).\n",
    "2. Then, use a groupby and an aggregation function to obtain the total revenue.\n",
    "3. BONUS: plot the result using `df.plot.bar()` or `df.plot()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Portfolio Analysis\n",
    "\n",
    "### Analysis: revenue across product categories?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next question: **Which product categories generate the most revenue?**\n",
    "\n",
    "Typical question to ask:\n",
    "* Which category dominates revenue? Do we risk of over-dependence?\n",
    "* Is there a drop-off after top 3 categories or any other long tail effect?\n",
    "* Are high-volume categories also high-value? Might lead into later analysis (avg. order value).\n",
    "\n",
    "We’ll use `groupby()` again, but this time by `category`. It works just like with months, but this helps us understand which types of products are performing best.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_revenue = df.groupby('category')[['revenue']].sum()\n",
    "category_revenue = category_revenue / category_revenue.sum() * 100\n",
    "\n",
    "category_revenue = category_revenue.sort_values(ascending=False, by='revenue')\n",
    "category_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic plot command\n",
    "category_revenue.plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: Average Order Value by Category\n",
    "\n",
    "Revenue alone doesn’t tell the full story. Some categories might generate fewer sales but have *higher order values*.\n",
    "\n",
    "Let’s calculate **average revenue per order** (AOV) for each product category.\n",
    "\n",
    "This helps answer: *Which categories sell for more money per order?*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_order_value = df.groupby('category')[['revenue']].mean()\n",
    "avg_order_value = avg_order_value.sort_values(by='revenue', ascending=False)\n",
    "avg_order_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_order_value.plot(\n",
    "    kind     ='bar', \n",
    "    color    ='mediumseagreen',\n",
    "    title    ='Average Order Value by Category',\n",
    "    xlabel   ='Product Category',\n",
    "    ylabel   ='Avg. Order Value',\n",
    "    figsize  =(10, 6),\n",
    "    fontsize =14\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mhm, an interesting pattern emerges, let's overlay this with our previous plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "bar_colors = ['green' if cat in ['Western Dress', 'Set'] else 'coral' for cat in category_revenue.index]\n",
    "\n",
    "category_revenue.plot(kind='bar', color='coral', ax=ax)\n",
    "\n",
    "for i, category in enumerate(category_revenue.index):\n",
    "    avg_cost = df[df['category'] == category]['revenue'].mean()\n",
    "    ax.text(i, category_revenue.values[i] +.1, f'€{avg_cost:.2f}', ha='center', fontsize=10)\n",
    "\n",
    "ax.annotate(\n",
    "    'High Potential?',\n",
    "    xy=(2, 15),\n",
    "    xytext=(2, 15 + 5),\n",
    "    arrowprops=dict(facecolor='black', shrink=0.15, width=2, headwidth=8),\n",
    "    ha='center',\n",
    "    fontsize=11,\n",
    "    fontweight='bold'\n",
    ")\n",
    "ax.annotate(\n",
    "    'High Potential?',\n",
    "    xy=(3, 15),\n",
    "    xytext=(2, 20),\n",
    "    arrowprops=dict(facecolor='black', shrink=0.15, width=2, headwidth=8),\n",
    "    ha='center',\n",
    "    fontsize=11,\n",
    "    fontweight='bold'\n",
    ")\n",
    "\n",
    "\n",
    "plt.title('Revenue by Product Category', fontsize=14)\n",
    "plt.xlabel('Product Category')\n",
    "plt.ylabel('Percentage of Total Revenue')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: Product Portfolio Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of each product category as a portfolio element. High revenue = popularity. High AOV = profitability per sale. Plotting these gives us a clear 2x2 matrix for strategy.\n",
    "\n",
    "\n",
    "|                             | **Low AOV** (below median)                           | **High AOV** (above median)                         |\n",
    "|-----------------------------|------------------------------------------------------|-----------------------------------------------------|\n",
    "| **Low Revenue** (left side) | ❌ **Underperformers**<br>Consider retiring or repositioning | 🎯 **Niche Upside**<br>Test with promos or better visibility |\n",
    "| **High Revenue** (right side) | 📦 **Volume Drivers**<br>Focus on logistics, bundling, efficiency | ⭐ **Premium Performers**<br>Upsell, promote, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate total revenue and AOV per category\n",
    "category_metrics = df.groupby('category').agg(\n",
    "    total_revenue   = ('revenue', 'sum'),\n",
    "    avg_order_value = ('revenue', 'mean')\n",
    ").reset_index()\n",
    "category_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You try it**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to scatter plot the total revenue v.s. median order value. The command you'll use is `.plot.scatter(x=...,y=...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a fancy version, which assumes you have already calculated the correct avg order value :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot\n",
    "category_metrics['revenue_10k'] = category_metrics['total_revenue'] / 10000\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "scatter = ax.scatter(\n",
    "    category_metrics['revenue_10k'],\n",
    "    category_metrics['avg_order_value'],\n",
    "    s=200, \n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "# Annotate each point with the category name\n",
    "for _, row in category_metrics.iterrows():\n",
    "    ax.text(row['revenue_10k'], row['avg_order_value'], row['category'], fontsize=9, ha='right')\n",
    "\n",
    "# Add reference lines for median revenue and median AOV\n",
    "median_revenue = category_metrics['revenue_10k'].median()\n",
    "median_aov     = category_metrics['avg_order_value'].median()\n",
    "\n",
    "ax.axhline(median_aov,     color='gray', linestyle='--', linewidth=1)\n",
    "ax.axvline(median_revenue, color='gray', linestyle='--', linewidth=1)\n",
    "\n",
    "# Titles and labels\n",
    "ax.set(\n",
    "    title='Product Categories: Revenue vs. Average Order Value',\n",
    "    xlabel='Total Revenue (€10,000)',\n",
    "    ylabel='Average Order Value (€)'\n",
    ")\n",
    "ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can also do this at the SKU level (which probably makes more sense for Amazon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate total revenue and AOV per SKU\n",
    "sku_metrics = df.groupby('base-SKU').agg(\n",
    "    total_revenue        = ('revenue', 'sum'),\n",
    "    median_order_value   = ('revenue', 'median')\n",
    ").reset_index()\n",
    "\n",
    "sku_metrics = sku_metrics[sku_metrics['total_revenue'] > 1000]\n",
    "\n",
    "# Scale revenue for plot readability\n",
    "sku_metrics['revenue_10k'] = sku_metrics['total_revenue'] / 10000\n",
    "\n",
    "# Create scatter plot\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "scatter = ax.scatter(\n",
    "    sku_metrics['revenue_10k'],\n",
    "    sku_metrics['median_order_value'],\n",
    "    s=100, alpha=0.7\n",
    ")\n",
    "\n",
    "# Annotate each point with the SKU (shortened if necessary)\n",
    "for _, row in sku_metrics.iterrows():\n",
    "    label = str(row['base-SKU'])[:15]  # truncate if SKUs are long\n",
    "    ax.text(row['revenue_10k'], row['median_order_value'], label, fontsize=10, ha='right')\n",
    "\n",
    "# Add reference lines for medians\n",
    "median_revenue = sku_metrics['revenue_10k'].median()\n",
    "median_aov     = sku_metrics['median_order_value'].median()\n",
    "\n",
    "ax.axhline(median_aov,     color='gray', linestyle='--', linewidth=1)\n",
    "ax.axvline(median_revenue, color='gray', linestyle='--', linewidth=1)\n",
    "\n",
    "# Titles and labels\n",
    "ax.set(\n",
    "    title='SKU Performance: Revenue vs. Median Order Value\\n(SKUs with > €1000 Revenue)',\n",
    "    xlabel='Total Revenue (€10,000)',\n",
    "    ylabel='Median Order Value (€)'\n",
    ")\n",
    "\n",
    "ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credits: original data source from [here](https://data.world/anilsharma87)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
